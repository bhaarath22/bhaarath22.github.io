<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CNN Model Inference Hub</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    <style>
        /* Custom styles for a polished and modern look */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #848689; /* A lighter, cleaner gray */
        }
        .btn {
            @apply font-semibold py-2.5 px-5 rounded-lg transition-all duration-300 ease-in-out shadow-md hover:shadow-lg focus:outline-none focus:ring-2 focus:ring-offset-2;
        }
        .btn-primary {
            @apply bg-indigo-600 text-white hover:bg-indigo-700 focus:ring-indigo-500;
        }
        .btn-secondary {
            @apply bg-gray-700 text-white hover:bg-gray-800 focus:ring-gray-600;
        }
        .btn-danger {
            @apply bg-red-600 text-white hover:bg-red-700 focus:ring-red-500;
        }
        .btn:disabled {
            @apply bg-indigo-400 text-white opacity-60 cursor-not-allowed shadow-none;
        }
        .card {
            @apply bg-white p-6 rounded-xl shadow-lg border border-gray-200;
        }
        /* Style for the display area to maintain aspect ratio and look clean */
        #display-area {
            aspect-ratio: 4 / 3;
            background-color: #e5e7eb; /* A slightly darker gray for contrast */
            overflow: hidden; /* Ensures content fits within the rounded corners */
        }
        #webcam-video, #uploaded-image {
            width: 100%;
            height: 100%;
            object-fit: cover; /* Ensures the video/image covers the area without distortion */
        }
    </style>
</head>
<body class="flex items-center justify-center min-h-screen">

    <div class="container mx-auto p-4 max-w-6xl w-full">
        <header class="text-center mb-2.5">
            <h1 class="text-4xl md:text-5xl font-extrabold text-gray-800 tracking-tight">CNN Model Inference Hub</h1>
            <p class="text-lg text-gray-500 mt-2">Interact with models using your webcam or images.</p>
        </header>

        <main class="grid grid-cols-1 lg:grid-cols-2 gap-8">

            <!-- Left Column: Controls -->
            <div class="flex flex-col">
                <!-- Controls Card -->
                <div class="card">
                    <h2 class="text-2xl font-bold text-gray-700 mb-4 border-b border-gray-200 pb-3">Controls</h2>
                    
                    <div class="mb-5">
                        <label for="model-select" class="block text-md font-medium text-gray-600 mb-2">1. Select Model</label>
                        <select id="model-select" class="w-full p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-indigo-500 focus:border-indigo-500 transition">
                            <option value="Plant Disease Recognition" selected>Plant Disease Recognition</option>
                            <option value="Emotion Detection">Emotion Detection</option>
                            <option value="Object Classifier">Object Classifier</option>
                            <option value="Digit Recognizer">Digit Recognizer</option>
                        </select>
                    </div>

                    <div class="mb-5">
                        <label class="block text-md font-medium text-gray-600 mb-2">2. Provide Input</label>
                        <div class="grid grid-cols-1 sm:grid-cols-2 gap-4">
                            <button id="webcam-btn" class="btn btn-secondary">Use Webcam</button>
                            <button id="stop-webcam-btn" class="btn btn-danger hidden">Stop Camera</button>
                            <button id="upload-btn" class="btn btn-secondary">Upload Image</button>
                            <input type="file" id="file-input" accept="image/*" class="hidden">
                        </div>
                    </div>
                    
                    <div>
                        <label class="block text-md font-medium text-gray-600 mb-2">3. Run Inference</label>
                         <button id="start-inference-btn" class="w-full btn btn-primary text-lg" disabled>
                            Start Inference
                        </button>
                    </div>
                </div>
            </div>

            <!-- Right Column: Display and Results -->
            <div class="flex flex-col space-y-8">
                <!-- Image/Video Display Card -->
                <div class="card flex items-center justify-center">
                    <div id="display-area" class="w-full rounded-lg flex items-center justify-center">
                        <video id="webcam-video" autoplay playsinline class="hidden rounded-lg"></video>
                        <img id="uploaded-image" src="#" alt="Uploaded content" class="hidden rounded-lg">
                        <span id="placeholder-text" class="text-gray-500 text-center p-4">Select an input source to begin</span>
                    </div>
                </div>
                
                <!-- Results Card -->
                <div id="results-section" class="card hidden">
                    <h2 class="text-2xl font-bold text-gray-700 mb-4 border-b border-gray-200 pb-3">Results</h2>
                    <!-- This is the more prominent "Message Box" -->
                    <div id="result-box" class="text-center mb-5 p-4 bg-indigo-50 rounded-lg border border-indigo-200">
                        <p class="text-xl text-gray-600">Prediction</p>
                        <p class="text-3xl font-bold text-indigo-800 mt-1" id="prediction-output">...</p>
                    </div>

                    <h3 class="text-xl font-semibold text-gray-700 mb-3">Analysis Report</h3>
                    <div class="space-y-2 text-gray-600 bg-gray-50 p-4 rounded-lg">
                        <p><strong>Confidence:</strong> <span id="confidence-output" class="font-mono text-gray-800">...</span></p>
                        <p><strong>Inference Time:</strong> <span id="time-output" class="font-mono text-gray-800">...</span></p>
                    </div>
                </div>
            </div>
        </main>
    </div>

<script>
document.addEventListener('DOMContentLoaded', () => {

    //======================================================================
    // 1. STATE MANAGEMENT
    //======================================================================
    const appState = {
        currentModel: 'Plant Disease Recognition',
        inputSource: null, // 'webcam' or 'file'
        webcamStream: null, // To hold the MediaStream object
    };

    //======================================================================
    // 2. DOM ELEMENT REFERENCES
    //======================================================================
    const modelSelect = document.getElementById('model-select');
    const webcamBtn = document.getElementById('webcam-btn');
    const stopWebcamBtn = document.getElementById('stop-webcam-btn');
    const uploadBtn = document.getElementById('upload-btn');
    const fileInput = document.getElementById('file-input');
    const startInferenceBtn = document.getElementById('start-inference-btn');

    const videoElement = document.getElementById('webcam-video');
    const imageElement = document.getElementById('uploaded-image');
    const placeholderText = document.getElementById('placeholder-text');
    
    const resultsSection = document.getElementById('results-section');
    const predictionOutput = document.getElementById('prediction-output');
    const confidenceOutput = document.getElementById('confidence-output');
    const timeOutput = document.getElementById('time-output');
    
    //======================================================================
    // 3. MOCK INFERENCE LOGIC
    //======================================================================
    /**
     * Simulates running a CNN model.
     * @param {HTMLImageElement|HTMLVideoElement|HTMLCanvasElement} imageData - The input image data.
     * @param {string} modelName - The name of the model to simulate.
     * @returns {Promise<{prediction: string, confidence: number}>} - A promise that resolves with the mock result.
     */
    const runInference = (imageData, modelName) => {
        return new Promise(resolve => {
            const processingTime = Math.random() * 450 + 50; // 50ms to 500ms
            
            setTimeout(() => {
                let result = {};
                const confidence = Math.random();
                switch (modelName) {
                    case 'Plant Disease Recognition':
                        const plants = ['Tomato - Early Blight', 'Potato - Late Blight', 'Corn - Common Rust'];
                        result = { prediction: plants[Math.floor(Math.random() * plants.length)], confidence };
                        break;
                    case 'Emotion Detection':
                        const emotions = ['Happy', 'Sad', 'Surprised', 'Neutral', 'Angry'];
                        result = { prediction: emotions[Math.floor(Math.random() * emotions.length)], confidence };
                        break;
                    case 'Object Classifier':
                        const objects = ['Keyboard', 'Mouse', 'Coffee Mug', 'Laptop'];
                        result = { prediction: objects[Math.floor(Math.random() * objects.length)], confidence };
                        break;
                    case 'Digit Recognizer':
                        result = { prediction: `Digit: ${Math.floor(Math.random() * 10)}`, confidence };
                        break;
                    default:
                        result = { prediction: 'Unknown Model', confidence: 0 };
                }
                resolve(result);
            }, processingTime);
        });
    };

    //======================================================================
    // 4. UI AND STATE UPDATE FUNCTIONS
    //======================================================================
    /**
     * Stops the active webcam stream and resets the UI.
     */
    const handleStopWebcam = () => {
        if (appState.webcamStream) {
            appState.webcamStream.getTracks().forEach(track => track.stop());
            appState.webcamStream = null;
        }
        // Reset UI elements
        videoElement.srcObject = null;
        videoElement.classList.add('hidden');
        placeholderText.textContent = "Select an input source to begin";
        placeholderText.classList.remove('hidden');

        // Reset state and buttons
        appState.inputSource = null;
        updateInferenceButtonState();
        webcamBtn.classList.remove('hidden');
        stopWebcamBtn.classList.add('hidden');
        resetResults();
    };

    /**
     * Updates the UI to enable/disable the inference button.
     */
    const updateInferenceButtonState = () => {
        if (appState.inputSource) {
            startInferenceBtn.disabled = false;
        } else {
            startInferenceBtn.disabled = true;
        }
    };
    
    /**
     * Resets the result display area to its initial state.
     */
    const resetResults = () => {
        resultsSection.classList.add('hidden');
        predictionOutput.textContent = '...';
        confidenceOutput.textContent = '...';
        timeOutput.textContent = '...';
    };

    //======================================================================
    // 5. EVENT HANDLERS
    //======================================================================
    /**
     * Handles changes to the model selection dropdown.
     */
    const handleModelChange = () => {
        appState.currentModel = modelSelect.value;
        console.log(`Model changed to: ${appState.currentModel}`);
        resetResults();
    };

    /**
     * Starts the webcam stream.
     */
    const startWebcam = async () => {
        // Ensure any previous stream is stopped.
        if (appState.webcamStream) {
            handleStopWebcam();
        }
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            appState.webcamStream = stream; // Save the stream to state
            videoElement.srcObject = stream;
            
            // Show video and hide others
            videoElement.classList.remove('hidden');
            imageElement.classList.add('hidden');
            placeholderText.classList.add('hidden');

            // Update state and UI
            appState.inputSource = 'webcam';
            updateInferenceButtonState();
            webcamBtn.classList.add('hidden');
            stopWebcamBtn.classList.remove('hidden');
            resetResults();
        } catch (error) {
            console.error("Error accessing webcam:", error);
            placeholderText.textContent = "Could not access webcam. Please grant permission.";
            placeholderText.classList.remove('hidden');
        }
    };

    /**
     * Handles the image upload process.
     * @param {Event} event - The file input change event.
     */
    const handleImageUpload = (event) => {
        const file = event.target.files[0];
        if (file) {
            // An image is being uploaded, so turn off the webcam.
            if (appState.webcamStream) {
                handleStopWebcam();
            }

            const reader = new FileReader();
            reader.onload = (e) => {
                imageElement.src = e.target.result;
                
                // Show image and hide others
                imageElement.classList.remove('hidden');
                videoElement.classList.add('hidden');
                placeholderText.classList.add('hidden');
                
                // Update state and UI
                appState.inputSource = 'file';
                updateInferenceButtonState();
                resetResults();
            };
            reader.readAsDataURL(file);
        }
    };

    /**
     * Main function to handle the start of the inference process.
     */
    const handleStartInference = async () => {
        if (!appState.inputSource) {
            console.warn("Inference started without an input source.");
            return;
        }

        startInferenceBtn.disabled = true;
        startInferenceBtn.textContent = 'Processing...';

        let inputData;
        if (appState.inputSource === 'webcam') {
            const canvas = document.createElement('canvas');
            canvas.width = videoElement.videoWidth;
            canvas.height = videoElement.videoHeight;
            canvas.getContext('2d').drawImage(videoElement, 0, 0, canvas.width, canvas.height);
            inputData = canvas;
        } else {
            inputData = imageElement;
        }

        const startTime = performance.now();
        const result = await runInference(inputData, appState.currentModel);
        const endTime = performance.now();
        const inferenceTime = endTime - startTime;

        // Update UI with the results
        predictionOutput.textContent = result.prediction;
        confidenceOutput.textContent = `${(result.confidence * 100).toFixed(1)}%`;
        timeOutput.textContent = `${inferenceTime.toFixed(0)} ms`;
        resultsSection.classList.remove('hidden');

        // Re-enable button
        startInferenceBtn.disabled = false;
        startInferenceBtn.textContent = 'Start Inference';
    };

    //======================================================================
    // 6. EVENT LISTENERS
    //======================================================================
    modelSelect.addEventListener('change', handleModelChange);
    webcamBtn.addEventListener('click', startWebcam);
    stopWebcamBtn.addEventListener('click', handleStopWebcam);
    uploadBtn.addEventListener('click', () => fileInput.click());
    fileInput.addEventListener('change', handleImageUpload);
    startInferenceBtn.addEventListener('click', handleStartInference);
    
    // Initialize the button state on page load
    updateInferenceButtonState();
});
</script>

</body>
</html>